# 网络原理

## 概论

### 因特网的协议栈层次

- 应用层: 网络应用程序及其应用层协议留存的地方（报文）
- 运输层: 提供应用层端点之间传送应用层报文的服务(TCP/UDP)（报文段）
- 网络层: 将数据报的网络层分组从一台主机移动到另一台主机(IP协议族)（数据报）
- 链路层: 将帧从一个网络元素移动到临近的网络元素,数据报从源到目的地,经过不同链路上不同链路层协议处理, 提供的服务取决于应用于该链路的特定链路层协议.(以太网/WiFi/PPP)（帧）
- 物理层: 将帧一个一个比特从一个节点移动到下一个节点
- 表示层：对数据进行翻译、加密和压缩
- 会话层：建立、管理和终止会话

### TCP/IP分层（4层）

网络接口层、 网际层、运输层、 应用层。

### 电路交换和分组交换

数据通过网络有两种基本方式:电路交换和分组交换。在电路交换网络中，沿着通信路径，为端系统之间通信所提供的资源(缓存、传输速率) 在通信会话期间会被预留，传统的电话网络是电路交换网络的例子。
在分组交换网络中，则没有预留带宽等通信资源，数据分组按需使用这些资源。 Internet 是分组交换网络。

- 电路交换

    电路交换网络中，当两台主机要通信时，网络在两台主机之间创建一条专用的端到端 连接，这个过程需要专门的信令协议(Signalling Protocol)。由于预留了资源，用户通话过程 中能够达到电路级性能。

- 电路交换网络中的多路复用

    电路交换中的链路通过频分多路复用或者时分多路复用实现带宽在多个用户之间分配。

    FDMA(Frequency Division Multiple Access)链路在连接期间为每条连接分配一个专用频 段。

    TDMA(Time Division Multiple Access)链路中时间被划分为固定区间的帧，并且每帧又被 划分为固定数量的时隙。TDMA 链路在每个帧中为一个连接指定一个时隙。
    
- 分组交换

    在计算机网络中，源主机将长报文划分为较小的数据块，称为分组。在源和目的地之间， 这些分组通过通信链路和分组交换机传送。    
    
    端系统通过通信链路和分组交换机连接到一起。 通信链路的物理介质主要包括同轴电缆、双绞线、光纤和无线电。
    
    分组交换机从输入端口接收到达的分组，并从它的输出端口转发该分组。路由器和链路层交换机是最常见的两种分组交换机。
    多数分组交换机使用存储转发传输机制。存储转发传输机制是指在交换机能够开始向 输出链路传输该分组的第一个比特之前，必须接收到整个分组。对于每条相连的链路，该分 组交换机具有一个输出缓存，它用于存储路由器准备发往那条链路的分组。
    
- 分组交换与电路交换比较

    分组交换是统计多路复用。 电路交换中如果用户没有通信，已分配频率或时间会被浪费。 由于一个特定用户一般不会持续处于活跃状态，因此分组交换可以通过同时转发多个用户的数据而最大化通信链路的传输性能，表现出优于电路交换的性能。这时链路传输能力将 在所有需要传输分组的用户中，以分组为单位进行分配。这种按需(而不是预分配)共享资源的方式被称为统计多路复用。

### 分组交换网中的时延

- 节点处理时延

    检查分组首部、检查分组比特级差错和决定将该分组发到何处所需要的时间是处理时延。 处理时延取决于路由器处理能力。高速路由器的处理时延通常是微秒或更低的数至级。
    
- 排队时延

    分组中输出端口队列中，等待传输时，它经厉排队时延。 一个分组的排队时延将取决于队列的长度，或者说取决于网络中的流量。实际的排队时延通常在毫秒到微秒级。
    
- 传输时延

    将分组传送到链路需要的时间。传输时延等于分组长度除以链路传输速率(网卡工作速率)。实际的传输时延通常在毫秒 到微秒级。
    
- 传播时延

    分组的一个比特从该链路的起点到终点所需要的时间是传播时延。 传播时延等于两台路由器之间的距离除以传播速率。在广域网中传播时延在毫秒的量级。
    

### ISP

（Internet Service Provider）就是因特网服务提供者的英文缩写。
    
- IXP

    (Internet eXchange Point,互联网交换点)就是这样一个方案，相当于在地区ISP之间直接相连进行交换分组，不需要走主干ISP。
    
    
    
![](img/ISP.jpg)

### 网络类型

![](img/网络类型.jpg)

### 网络拓扑类型

![](img/网络拓扑类型.jpg)
    
    
    
## 应用层

### 套接字

同一台主机内应用层和运输层的接口，套接字需要客户端地址（由操作系统提供） 、客户端端口号（由操作系统提供）、服务器端地址、服务器端口号（套接字编程提供）

### RTT

指一个短分组从客户到服务器再返还客户所化的时间

### HTTP报文内容

- 状态行：版本/状态/状态信息（200-301-400-404-505）
- 请求行：方法字段（GET-POST-HEAD-PUT-DELETE）/URL/版本
- 首部行
- 实体体

### Get和POST的区别

- 根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。
- 根据HTTP规范，POST表示可能修改变服务器上的资源的请求。
- GET请求的数据会附在URL之后
- GET方式提交的数据最多只能是1024字节，理论上POST没有限制，可传较大量的数据
- POST的安全性要比GET的安全性高

### DNS 提供的服务

- 解析 IP 地址
- 主机别名：主机别名比主机规范名更容易记忆，例如http://www.mit.edu，其真实的服务器名字(主机规范名)并不是http://www.mit.edu
- 邮件服务器别名：电子邮件应用程序可以调用 DNS，对提供的邮件服务别名进行解析，以获得该主机的规范主机名及其 IP。事实上，MX 记录允许一个公司的邮件服务器和 WEB 服务器拥有相同的主机名，例如一个公司的 WEB 服务器和邮件服务器都能叫做 ENTERPRISE.COM
- 负载均衡：一个IP地址集合对应于同一个规范主机名。DNS数据库中存储着这些IP地址集合。当客户机为映射到这个IP地址集合的名字发出一个DNS请求时，该服务器用包含全部这些地址的消息进行回答，但在每个回答中轮回这些地址排放的顺序。

### 域名的层级

DNS服务器怎么会知道每个域名的IP地址呢？答案是分级查询。

请仔细看前面的例子，每个域名的尾部都多了一个点。

比如，域名math.stackexchange.com显示为math.stackexchange.com.。这不是疏忽，而是所有域名的尾部，实际上都有一个根域名。

举例来说，www.example.com真正的域名是www.example.com.root，简写为www.example.com.。因为，根域名.root对于所有域名都是一样的，所以平时是省略的。

根域名的下一级，叫做"顶级域名"（top-level domain，缩写为TLD），比如.com、.net；再下一级叫做"次级域名"（second-level domain，缩写为SLD），比如www.example.com里面的.example，这一级域名是用户可以注册的；再下一级是主机名（host），比如www.example.com里面的www，又称为"三级域名"，这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的。

总结一下，域名的层级结构如下。

```
主机名.次级域名.顶级域名.根域名

# 即

host.sld.tld.root

```

### DNS服务器类型

- 根ONS服务器。在因特网上有13个根DNS服务器(标号为A到M)，其中大部分位于北美洲。
- 顶级域(TLD)服务器。这些服务器负责顶级域名(如COM,ORG,GOV和所有国家的顶级域名(如CN)。
- 权威DNS服务器。将主机的名字映射为IP地址，由一个单位的权威DNS服务器负责保存这些记录。另一种方法是支付费用将这些记录存储在某个ISP的权威DNS服务器中。
- 本地DNS服务器。严格来说并不属于DNS服务器的层次结构，本地DNS服务器通常与主机相隔不超过几个路由器。当主机发出DNS请求时，该请求被发往本地DNS服务器，它起着代理的作用，并将域名简析请求转发到DNS服务器层次结构中。

### DNS 查询原理

假定一个DNS客户机要确定主机名http://www.mit.edu的 IP 地址。

- 域名查询主机的 DNSClient 向本地域名服务器发起一个查询，当主机与某个 ISP 连接时，该 ISP 会提供本地 DNS 服务器的IP地址。这一步是递归查询，因为本地 DNS 服务器没有立即返回，而是自己作为客户端和其他 DNS 服务器沟通。

- 本地域名服务器首先获取 url 最后一个域名 .root, 因而开始与根服务器之一联系。根服务器根据域名倒数第二个地址 edu, 取得顶级域名 edu 的 TLD 服务器的 IP 地址。这一步是迭代查询，因为根服务器立刻向本地 DNS 服务器返回了结果。

- 本地域名服务器然后与这些 TLD 服务器之一联系，顶级域 DNS 服务器获取了倒数第三地址 mid，取得 http://mit.edu 权威服务器的 IP 地址。这一步仍然为迭代查询。

- 本地域名服务器为联系权威服务器，权威 DNS 服务器根据 www，返回 www 主机的 IP 地址。

- 最后，本地域名服务器将结果返还给 DNSClient，操作系统将结果作为函数调用返回值给应用程序。

### DNS 报文

- A：地址记录（Address），返回域名指向的IP地址。
- NS：域名服务器记录（Name Server），返回保存下一级域名信息的服务器地址。该记录只能设置为域名，不能设置为IP地址。
- MX：邮件记录（Mail eXchange），返回接收电子邮件的服务器地址。
- CNAME：规范名称记录（Canonical Name），返回另一个域名，即当前查询的域名是另一个域名的跳转，详见下文。
- PTR：逆向查询记录（Pointer Record），只用于从IP地址查询域名，详见下文。

### DNS 查询实例

dig命令的+trace参数可以显示DNS的整个分级查询过程。

```
 dig +trace math.stackexchange.com

```

上面命令的第一段列出根域名.的所有NS记录，即所有根域名服务器。

![](img/DNS1.png)


根据内置的根域名服务器IP地址，DNS服务器向所有这些IP地址发出查询请求，询问 math.stackexchange.com 的顶级域名服务器 com. 的 NS 记录。最先回复的根域名服务器将被缓存，以后只向这台服务器发请求。

值得注意的是 NS 记录的仍然是域名，是顶级域的域名，并没有真正的 IP 地址。这些顶级域域名的 IP 是存放在 A 记录里面的。

也正是因为这个，添加 DNS 服务器的时候，需要同时添加两条记录，NS 记录与 A 记录。

接着是第二段。

![](img/DNS2.png)


上面结果显示.com域名的13条NS记录，同时返回的还有每一条记录对应的IP地址。

然后，DNS服务器向这些顶级域名服务器发出查询请求，询问math.stackexchange.com的次级域名stackexchange.com的NS记录。

![](img/DNS3.png)

上面结果显示stackexchange.com有四条NS记录，同时返回的还有每一条NS记录对应的IP地址。

然后，DNS服务器向上面这四台NS服务器查询math.stackexchange.com的主机名。


![](img/DNS4.png)

上面结果显示，math.stackexchange.com有4条A记录，即这四个IP地址都可以访问到网站。并且还显示，最先返回结果的NS服务器是ns-463.awsdns-57.com，IP地址为205.251.193.207。


### DNS缓存

为了改善时延性能并减少在因特网上传输的DNS消息数量，DNS广泛使用了缓存技术。DNS缓存的原理非常简单。在请求链中，当一个DNS服务器接收一个DNS回答时，服

务器能将回答中的信息缓存在本地存储器。

## 运输层

### 运输层协议提供哪些服务？

- 可靠数据传输。分组可能在计算机网络中丢失。确保应用程序一端发送的数据正确地、完全地交付给该应用程序的另一端。
- 吞吐量：有些应用例如网络电话对话音传输有最小的带宽要求，当话音以32kbps的速率进行编码，那么在通话过程中一直以这个速率向网络发送数据，并向接收应用程序交付数据。如果传输层不能提供这种吞吐量保证，那么该应用程序或以较低速率进行编码，或者放弃发送。而弹性应用能够根据需要充分利用可供使用的吞吐量。电子邮件、文件传输以及Web传输都属于弹性应用。
- 定时：因特网电话中较长的时延会导致会话中不自然的停顿。在网络游戏和虚拟互动环境中，在动作及响应之间较长的时延会使游戏失去真实感。在非实时的应用中，对端到端的时延没有严格的约束。
- 安全：能够为应用程序提供一种或多种安全性服务。


如果网络层无法提供时延或带宽保障，那运输层也无法保证。

即使网络层分组丢失、篡改和冗余，运输层可以提供数据可靠服务和安全服务


### UDP 和 TCP 的区别

- 可以提供的服务：UDP 只能提供数据交付和差错检查，而 TCP 可以提供数据交付、差错检查、可靠性数据交付、安全性、流量控制、拥塞控制
- TCP提供面向连接的，UDP提供的是非面向连接的
- TCP是一种流模式的协议，UDP是一种数据报模式的协议，TCP 传输单位称为 TCP 报文段，UDP 传输单位称为用户数据报，基于流的数据没有边界（长度）限制，而基于数据报的服务，每个 UDP 数据报都有一个长度，接收端必须以该长度为最小单位将其所有内容一次性读出。TCP 模块发出的 TCP 报文段的个数与应用程序执行的写操作次数是没有固定数量关系的。对于 UDP 连接，发送端写的次数据与读的次数是一致的，这也是基于数据报的服务的特点。
- 运行的协议：DNS/DHCP/TFTP

### UDP 的优点

立即发送、无需连接建立、无连接状态、分组首部开销小

### UDP 报文结构

![](img/UDP.jpeg)

### TCP 报文结构

![](img/TCP1.jpg)

- 窗口大小：16位字段，这个字段定义的是发送TCP的窗口大小，以字节为单位。窗口最大长度是65535字节，这个值通常被称为接收窗口（rwnd）,并由接收方来决定。这种情况下，发送方必须服从接收方的指示。
- 该字段占用2字节，与URG代码位一起使用并且申明及时使存在着缓冲区溢出也必须紧急接收的数据末端。因此，如果有些数据需要不按照顺序被送往目的应用程序，那么发送端的应用程序必须利用紧急数据参数通知TCP。
- URG 紧急数据（urgent data）---这是一条紧急信息
- ACK 确认已收到段
- PSH 请求在缓冲区尚未填满时发送消息，注意TCP可以等待缓冲区填满之后再发送段，如果需要立即传送，应用程序必须利用push参数来通知协议。
- RST 申请重置连接
- SYN 此消息用于在建立连接时同步传输数据的计时器。
- FIN 该属性申明发送端已经发送出被传输数据的最后一个字节。

### TCP 可靠性数据传输原理

- 最大允许数N（窗口长度）/基序号SF/下一个序号SN/接受基序号RF/接受下一个序号RN累计确认
- 发送方：
    - 上层调用：窗口是否满（SN = SF + N）/启动定时器
    - 超时事件：重传引起超时的一个分组/重启定时器
    - 收到ACK（SF<ACK<=SN）：表明接受到了n以前所有分组/SF = ACK/重启定时器/终止定时器
    - 收到ACK（ACK<=SF or ACK>SN） || 错误ACK：丢弃
    - 快速重传：得到3个冗余ACK，重传丢失报文段
* 接收方：
    - 收到正确分组 && 分组 = RF：更新RF，将RF更新至没有接受的分组上（可能会有失序分组在缓存）/等待500ms，若没有分组，则发送ACK = RF + 1
    - 收到正确分组 && t < 500ms && 分组 = RF: 立即发送ACK = RF +1
    - 收到正确分组 && 分组 > RF && 分组 < RN:立即发送ACK = RF
    - 收到错误分组 || 分组 < RF || 分组 >= RN :丢弃

### TCP三次握手

- 第一步：客户端TCP首先向服务器端TCP发送特殊TCP报文段，不含应用层数据，标志位SYN置为1（SYN报文段），此外客户端随机选择一个初始序号（client_isn），放入报文段序号字段中。 
- 第二步：服务器提取SYN报文段，为TCP配置缓存和变量，并向客户发送允许连接的报文段。报文段中，SYN置为1，确认号置为client_isn +1,服务器选择自己初始序号（server_isn），此报文段又称SYNACK报文段
- 第三步：客户收到报文段后，也要分配连接缓存和变量。再次向服务器发送报文段，确认号为server_isn+1,SYN为0，可以有应用层数据
- 客户端：CLOSE->(发送SYN)->SYN_SENT->(接受SYN&ACK,发送ACK)->ESTABLISHED
- 服务端：LISTEN->(接受SYN,发送ACK)->SYN_RCVD->(接受ACK，不发送)->ESTABLISHED

![](img/TCP2.jpg)

### 三次握手动画演示

![](img/TCP7.gif)

![](img/TCP8.gif)

### 为什么 TCP 要三次握手而不是二次或四次

- 为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。
- TCP作为一种可靠传输控制协议，其核心思想：既要保证数据可靠传输，又要提高传输的效率，而用三次恰恰可以满足以上两方面的需求！TCP连接握手，握的是啥？通信双方数据原点的序列号！只有三次握手才能恰好的交换并且确认对方的起始序列号

>
TCP连接的一方A，由操作系统动态随机选取一个32位长的序列号（Initial Sequence Number），假设A的初始序列号为1000，以该序列号为原点，对自己将要发送的每个字节的数据进行编号，1001，1002，1003…，并把自己的初始序列号ISN告诉B，让B有一个思想准备，什么样编号的数据是合法的，什么编号是非法的，比如编号900就是非法的，同时B还可以对A每一个编号的字节数据进行确认。如果A收到B确认编号为2001，则意味着字节编号为1001-2000，共1000个字节已经安全到达。

>
>同理B也是类似的操作，假设B的初始序列号ISN为2000，以该序列号为原点，对自己将要发送的每个字节的数据进行编号，2001，2002，2003…，并把自己的初始序列号ISN告诉A，以便A可以确认B发送的每一个字节。如果B收到A确认编号为4001，则意味着字节编号为2001-4000，共2000个字节已经安全到达。
>
>二次握手的过程：
>
>2.1 A 发送同步信号 + A's Initial sequence number 
>
>2.2 B发送同步信号SYN + B's Initial sequence number + B's ACK sequence number
>
>这里有一个问题，A与B就A的初始序列号达成了一致，这里是1000。但是B无法知道A是否已经接收到自己的同步信号，如果这个同步信号丢失了，A和B就B的初始序列号将无法达成一致。
>
>于是TCP的设计者将SYN这个同步标志位SYN设计成占用一个字节的编号（FIN标志位也是），既然是一个字节的数据，按照TCP对有数据的TCP segment 必须确认的原则，所以在这里A必须给B一个确认，以确认A已经接收到B的同步信号。

### TCP 的半连接队列与全连接队列

![](img/TCP4.jpg)

如上图所示，这里有两个队列：syns queue(半连接队列)和accept queue(全连接队列)。三次握手中，服务端接收到客户端的SYN报文后，把相关信息放到半连接队列中，同时回复SYN+ACK给客户端。 第三步的时候服务端收到客户端的ACK，如果这时全连接队列没满，那么从半连接队列拿出相关信息放入到全连接队列中，否则按 tcp_abort_on_overflow的值来执行相关操作，直接抛弃或者过一段时间在重试。

### SYN 泛洪是什么

为了创建拒绝服务，攻击者利用这样的漏洞，即在接收到初始SYN数据包之后，服务器将用一个或多个SYN / ACK数据包进行响应，并等待握手中的最后一步。这是它的工作原理：

攻击者向目标服务器发送大量SYN数据包，通常会使用欺骗性的IP地址。

然后，服务器响应每个连接请求，并留下开放端口准备好接收响应。

当服务器等待从未到达的最终ACK数据包时，攻击者继续发送更多的SYN数据包。每个新的SYN数据包的到达导致服务器暂时维持新的开放端口连接一段时间，一旦所有可用端口被使用，服务器就无法正常工作。

![](img/TCP5.jpg)

在网络中，当服务器断开连接但连接另一端的机器没有连接时，连接被认为是半开的。在这种类型的DDoS攻击中，目标服务器不断离开打开的连接，等待每个连接超时，然后端口再次可用。结果是这种攻击可以被认为是“半开攻击”。

SYN洪水可以以三种不同的方式发生：直接攻击IP地址不被欺骗的SYN Flood被称为直接攻击。欺骗性攻击：恶意用户也可以欺骗他们发送的每个SYN数据包上的IP地址；分布式攻击（DDoS）：如果使用僵尸网络创建攻击，则将攻击溯源到源的可能性很低。

#### 如何减轻SYN洪水攻击？

- 增加积压队列
- 回收最早的半开TCP连接
- SYN cookie：这个策略涉及服务器创建一个cookie。为了避免在积压已经被填满的情况下连接丢失的风险，服务器使用SYN-ACK数据包对每个连接请求进行响应，然后从积压中删除SYN请求，从存储器中删除请求并使端口打开，准备建立新的连接。如果连接是合法请求，并且最终的ACK数据包从客户端计算机发送回服务器，则服务器将重建（有一些限制）SYN积压队列条目。

### 其他问题

- ISN代表什么？意义何在？

ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。

- ISN是固定不变的吗？

动态随机。

- ISN为何要动态随机？

增加安全性，为了避免被第三方猜测到，从而被第三方伪造的RST报文Reset。

- 还有吗？

ISN动态随机使得每个tcp session的字节序列号没有重叠，如果出现tcp五元组冲突这种极小概率情况的发生，一个session的数据也不会被误认为是另一个session的。

- 刚才你提到第三方可以伪造RST报文，需要满足什么条件才能得逞？

需要sequence number 位于对方的合法接收窗口内。 而由于ISN是动态随机的，猜出对方合法接收窗口难度加大。如果ISN = 0，那么猜出的难度就大大降低。

- 三次握手的第一次可以携带数据吗？为何？

不可以，三次握手还没有完成。

- 对方难道不可以将数据缓存下来，等握手成功再提交给应用程序？

这样会放大SYN FLOOD攻击。如果攻击者伪造了成千上万的握手报文，携带了1K+ 字节的数据，而接收方会开辟大量的缓存来容纳这些巨大数据，内存会很容易耗尽，从而拒绝服务。

- 第三次可以携带数据吗？为何？

可以。能够发出第三次握手报文的主机，肯定接收到第二次(服务器)握手报文，对吗？因为伪造IP的主机是不会接收到第二次报文的。所以，能够发出第三次握手报文的，应该是合法的用户。尽管服务器侧的状态还没有“established”，接收到第三次握手的瞬间，状态就会切换为“established”，里面携带的数据按照正常流程走就好。  

- 看到有人说，只看到过TCP状态位为 ’FIN +ACK’，但从来没有看过状态位只有 ‘FIN’，你应该怎样给他解释？

RFC793明确规定，除了第一个握手报文SYN除外，其它所有报文必须将ACK = 1。

- 很好，RFC规定的背后肯定有合理性的一面，能否深究一下原因？

TCP作为一个可靠传输协议，其可靠性就是依赖于收到对方的数据，ACK对方，这样对方就可以释放缓存的数据，因为对方确信数据已经被接收到了。但TCP报文是在IP网络上传输，丢包是家常便饭，接收方要抓住一切的机会，把消息告诉发送方。最方便的方式就是，任何我方发送的TCP报文，都要捎带着ACK状态位。

- ACK状态位单独能承担这个消息传递的任务吗？

不能！需要有 Acknowledge Number配合才行。如果我方发出的Acknowledge Number == 10001，那意味着序列号10000及之前的字节已经成功接收。如果对方占据字节序列号10000是应用层数据，那么就是确认应用层数据。如果对方占据字节序列号10000是’FIN’状态位，那么就是确认接收到对方的’FIN’。

### TCP 四次挥手过程

- 第一步：客户端TCP发送一个报文段，将其FIN标志位置为1
- 第二步：服务器收到后，将会向客户端发送确认报文段
- 第三步：服务器发送终止报文段，其FIN标志位为1
- 第四步：客户端收到后，向服务器发送确认报文段
- 客户端：连接->(发送FIN)->FIN_WAIT_1->(接受ACK)->FIN_WAIT_2->(接受FIN，发送ACK)->TIME_WAIT->(30s)->CLOSE
- 服务端：连接->(接受FIN,发送ACK)->CLOSE_WAIT->(发送FIN)->LAST_ACK->(接受ACK，不发送)->CLOSED

![](img/TCP11.jpg)

### 四次挥手动画演示

![](img/TCP9.gif)


![](img/TCP10.gif)

### TCP为什么是四次挥手，而不是三次

因为TCP是全双工通信的   

- 第一次挥手     因此当主动方发送断开连接的请求（即FIN报文）给被动方时，仅仅代表主动方不会再发送数据报文了，但主动方仍可以接收数据报文。    
- 第二次挥手     被动方此时有可能还有相应的数据报文需要发送，因此需要先发送ACK报文，告知主动方“我知道你想断开连接的请求了”。这样主动方便不会因为没有收到应答而继续发送断开连接的请求（即FIN报文）。   
- 第三次挥手    被动方在处理完数据报文后，便发送给主动方FIN报文；这样可以保证数据通信正常可靠地完成。发送完FIN报文后，被动方进入LAST_ACK阶段（超时等待）。   
- 第四挥手    如果主动方及时发送ACK报文进行连接中断的确认，这时被动方就直接释放连接，进入可用状态。


### 四次挥手中的 TIME_WAIT 的用途

- 为了保证客户端发送的最后一个ack报文段能够到达服务器。因为这最后一个ack确认包可能会丢失，然后服务器就会超时重传第三次挥手的fin信息报，然后客户端再重传一次第四次挥手的ack报文。如果没有这2msl，客户端发送完最后一个ack数据报后直接关闭连接，那么就接收不到服务器超时重传的fin信息报(此处应该是客户端收到一个非法的报文段，而返回一个RST的数据报，表明拒绝此次通信，然后双方就产生异常，而不是收不到。)，那么服务器就不能按正常步骤进入close状态。那么就会耗费服务器的资源。当网络中存在大量的timewait状态，那么服务器的压力可想而知。

- 在第四次挥手后，经过2msl的时间足以让本次连接产生的所有报文段都从网络中消失，这样下一次新的连接中就肯定不会出现旧连接的报文段了。也就是防止我们上一篇文章 为什么tcp是三次握手而不是两次握手？ 中说的：已经失效的连接请求报文段出现在本次连接中。如果没有的话就可能这样：这次连接一挥手完马上就结束了，没有timewait。这次连接中有个迷失在网络中的syn包，然后下次连接又马上开始，下个连接发送syn包，迷失的syn包忽然又到达了对面，所以对面可能同时收到或者不同时间收到请求连接的syn包，然后就出现问题了。

### 存在大量的 TIME_WAIT 该如何处理

- net.ipv4.tcp_timestamps = 1

    RFC 1323 在 TCP Reliability一节里，引入了timestamp的TCP option，两个4字节的时间戳字段，其中第一个4字节字段用来保存发送该数据包的时间，第二个4字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。

    tcp_tw_reuse 和 tcp_tw_recycle就依赖这些时间字段。

- net.ipv4.tcp_tw_reuse = 1
    
    字面意思，reuse TIME_WAIT状态的连接。

    时刻记住一条socket连接，就是那个五元组，出现TIME_WAIT状态的连接，一定出现在主动关闭连接的一方。所以，当主动关闭连接的一方，再次向对方发起连接请求的时候（例如，客户端关闭连接，客户端再次连接服务端，此时可以复用了；负载均衡服务器，主动关闭后端的连接，当有新的HTTP请求，负载均衡服务器再次连接后端服务器，此时也可以复用），可以复用TIME_WAIT状态的连接。

    通过字面解释，以及例子说明，你看到了，tcp_tw_reuse应用的场景：某一方，作为客户端，需要不断的通过“短连接”连接其他服务器，总是自己先关闭连接(TIME_WAIT在自己这方)，关闭后又不断的重新连接对方。

    那么，当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。

    这个配置，依赖于连接双方，同时对timestamps的支持。同时，这个配置，仅仅影响outbound连接，即做为客户端的角色，连接服务端[connect(dest_ip, dest_port)]时复用TIME_WAIT的socket。

- net.ipv4.tcp_tw_recycle = 1

    字面意思，销毁掉 TIME_WAIT。

    当开启了这个配置后，内核会快速的回收处于TIME_WAIT状态的socket连接。多快？不再是2MSL，而是一个RTO（retransmission timeout，数据包重传的timeout时间）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。

    有了这个配置，还是需要保障丢失重传或者延迟的数据包，不会被新的连接(注意，这里不再是复用了，而是之前处于TIME_WAIT状态的连接已经被destroy掉了，新的连接，刚好是和某一个被destroy掉的连接使用了相同的五元组而已)所错误的接收。在启用该配置，当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。

    这个配置，依赖于连接双方对timestamps的支持。同时，这个配置，主要影响到了inbound的连接（对outbound的连接也有影响，但是不是复用），即做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT状态的socket处于服务端，服务端快速的回收该状态的连接。

    由此，如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉)。
    
- SO_REUSEADDR
    
    假设是server主动关闭连接后异常终止。则由于它总是使用用一个知名serverport号，所以连接的time_wait状态将导致它不能重新启动。只是我们能够通过socket的选项SO_REUSEADDR来强制进程马上使用处于time_wait状态的连接占用的port。

通过socksetopt设置后，即使sock处于time_wait状态，与之绑定的socket地址也能够马上被重用。


### 存在大量 CLOSE_WAIT 状态

在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。

所以如果将大量CLOSE_WAIT的解决办法总结为一句话那就是：查代码。


### TCP 状态转移

![](img/TCP6.jpg)

![](img/TCP14.png)

### 数据流和数据报模式的区别

TCP和UDP都是传输层的协议，TCP协议的数据传输单位是报文段（segment），UDP协议的数据传输单位是用户数据报（datagram），上面应用层的数据单位是报文（message）

TCP的segment就是段的意思，也就是说TCP是把数据看成一连串字节流，当应用层传下来的报文（message）太长了，TCP是会把报文切片的，所以TCP的segment的意思是说：我的segment可能是报文（message）的某一段。UDP的单位是datagram，UDP拿到应用层传下来的报文，不会切分，应用层给UDP的数据多大，UDP不切分，加个首部就往下面的网络层传。

有人管IP协议的数据单位叫IP数据报（IP datagram)，其实叫分组（packet)更合适。IP协议跟TCP协议一样，也是面向数据流的（把数据看作一连串字节流）。如果网络层的IP协议拿到UDP传给自己的用户数据报（datagram），发现UDP给的报文太大了，就切分。切分后的东西叫IP分片（IP fragment）。

>
打个比方比喻TCP，你家里有个蓄水池，你可以里面倒水，蓄水池上有个龙头，你可以通过龙头将水池里的水放出来，然后用各种各样的容器装（杯子、矿泉水瓶、锅碗瓢盆）接水。上面的例子中，往水池里倒几次水和接几次水是没有必然联系的，也就是说你可以只倒一次水，然后分10次接完。另外，水池里的水接多少就会少多少；往里面倒多少水，就会增加多少水，但是不能超过水池的容量，多出的水会溢出。结合TCP的概念，水池就好比接收缓存，倒水就相当于发送数据，接水就相当于读取数据。好比你通过TCP连接给另一端发送数据，你只调用了一次write， 发送了100个字节，但是对方可以分10次收完，每次10个字节；你也可以调用10次write，每次10个字节，但是对方可以一次就收完。（假设数据都 能到达）但是，你发送的数据量不能大于对方的接收缓存（流量控制），如果你硬是要发送过量数据，则对方的缓存满了就会把多出的数据丢弃。

>
UDP 和TCP不同，发送端调用了几次write，接收端必须用相同次数的read读完。UPD是基于报文的，在接收的时候，每次最多只能读取一个报文，报文和 报文是不会合并的，如果缓冲区小于报文长度，则多出的部分会被丢弃。也就说，如果不指定MSG_PEEK标志，每次读取操作将消耗一个报文。

>
其实，这种不同是由TCP和UDP的特性决定的。TCP是面向连接的，也就是说，在连接持续的过程中，socket中收到的数据都是由同一台主机发出的（劫持什么的不考虑），因此，知道保证数据是有序的到达就行了，至于每次读取多少数据自己看着办。而 

>
UDP是无连接的协议，也就是说，只要知道接收端的IP和端口，且网络是可达的，任何主机都可以向接收端发送数据。这时候，如果一次能读取超过一个报文的 数据，则会乱套。比如，主机A向发送了报文P1，主机B发送了报文P2，如果能够读取超过一个报文的数据，那么就会将P1和P2的数据合并在了一起，这样 的数据是没有意义的。

>

### TCP拥塞控制

- 慢启动(超时 RTO 丢包)
    - 开始状态：cwnd值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS，当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数上升。
    - 丢包事件：cwnd设置为1，并且ssthresh = cwnd / 2
    - 超过阈值：转为拥塞避免模式
    - 3个冗余 ：如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需要等到重传定时器超时，所以叫做快速重传，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法。将ssthresh减半，cwnd = ssthresh + 3*MSS(或者cwnd = 1)，转为快速恢复
- 拥塞避免(超过阈值)
    - ACK事件：每次加MSS(MSS/cwnd)
    - 丢包事件：cwnd设置为1，并且ssthresh = cwnd / 2，转为慢启动
    - 3个冗余 ：将ssthresh减半，cwnd = ssthresh + 3*MSS(或者 cwnd = 1)，转为快速恢复  
- 快速恢复(冗余 3 个 ACK)
    - ACK冗余：如果再收到冗余 ACK，那么cwnd大小增加一。Tahoe将cwnd = 1指数增长，Reno将cwnd = ssthresh + 3*MSS,线性增长
    - 丢包事件：cwnd设置为1，并且ssthresh = cwnd / 2，转为慢启动
    - ACK预期：如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。
- AIMD：加性增，乘性减


![](img/TCP13.jpg)

### 多路分解与多路复用

- 多路分解：将运输层报文段的数据交付到正确的套接字的工作
- 多路复用：在源主机从不同套接字中收集数据块，并未每个数据块封装上首部信息，从而生成报文段，然后将报文段传递给网络层的工作
