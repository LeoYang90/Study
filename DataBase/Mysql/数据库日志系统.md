# 数据库日志系统

## Mysql redo log

### 基础概念

与查询流程不不⼀样的是，更新流程还涉及两个重要的⽇志模块，它们正是redo log(重做⽇志)和 binlog(归档⽇志)。

如果有⼈人要赊账或者还账的话，掌柜⼀一般有两种做法:

- 一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉; 
- 另⼀一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来 核算。

在⽣生意红⽕火柜台很忙时，掌柜⼀定会选择后者。

同样，在 MySQL ⾥里里也有这个问题，如果每⼀一次的更更新操作都需要写进磁 盘，然后磁盘也要找到对应的那条记录，然后再更更新，整个过程 IO 成 本、查找成本都很⾼高。为了了解决这个问题，MySQL 的设计者就⽤用了了类似 酒店掌柜粉板的思路路来提升更更新效率。

⽽而粉板和账本配合的整个过程，其实就是 MySQL ⾥里里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写⽇日志，再 写磁盘，也就是先写粉板，等不不忙的时候再写账本。

具体来说，当有⼀一条记录需要更更新的时候，InnoDB 引擎就会先把记录写 到 redo log(粉板)⾥里里⾯面，并更更新内存，这个时候更更新就算完成了了。同 时，InnoDB 引擎会在适当的时候，将这个操作记录更更新到磁盘⾥里里⾯面，⽽而 这个更更新往往是在系统⽐比较空闲的时候做，这就像打烊以后掌柜做的事。

如果今天赊账的不不多，掌柜可以等打烊后再整理理。但如果某天赊账的特别 多，粉板写满了了，⼜又怎么办呢?这个时候掌柜只好放下⼿手中的活⼉儿，把粉 板中的⼀一部分赊账记录更更新到账本中，然后把这些记录从粉板上擦掉，为 记新账腾出空间。

与此类似，InnoDB 的 redo log 是固定⼤大⼩小的，⽐比如可以配置为⼀一组 4 个 ⽂文件，每个⽂文件的⼤大⼩小是 1GB，那么这块“粉板”总共就可以记录 4GB 的 操作。从头开始写，写到末尾就⼜又回到开头循环写，如下⾯面这个图所示。

![](img/redolog1.png)

write pos 是当前记录的位置，⼀一边写⼀一边后移，写到第 3 号⽂文件末尾后就回到 0 号⽂文件开头。checkpoint 是当前要擦除的位置，也是往后推移 并且循环的，擦除记录前要把记录更更新到数据⽂文件。

write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以⽤用来记录 新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了了，这时候不不 能再执⾏行行新的更更新，得停下来先擦掉⼀一些记录，把 checkpoint 推进⼀一 下。

有了了 redo log，InnoDB 就可以保证即使数据库发⽣生异常重启，之前提交 的记录都不不会丢失，这个能⼒力力称为crash-safe。

要理理解 crash-safe 这个概念，可以想想我们前⾯面赊账记录的例例⼦子。只要 赊账记录记在了了粉板上或写在了了账本上，之后即使掌柜忘记了了，⽐比如突然 停业⼏几天，恢复⽣生意后依然可以通过账本和粉板上的数据明确赊账账⽬目。

### 数据写⼊入后的最终落 盘，是从 redo log 更更新过来的还是从 buffer pool 更更 新过来的呢?

redo log 并没有记录数据⻚页的完整数据，所以它并没有能⼒力力⾃自⼰己 去更更新磁盘数据⻚页，也就不不存在“数据最终落盘，是由 redo log 更更新过 去”的情况。

-  如果是正常运⾏行行的实例例的话，数据⻚页被修改以后，跟磁盘的数据⻚页不不 ⼀一致，称为脏⻚页。最终数据落盘，就是把内存中的数据⻚页写盘。这个 过程，甚⾄至与 redo log 毫⽆无关系。
- 在崩溃恢复场景中，InnoDB如果判断到⼀一个数据⻚页可能在崩溃恢复 的时候丢失了了更更新，就会将它读到内存，然后让 redo log 更更新内存内 容。更更新完成后，内存⻚页变成脏⻚页，就回到了了第⼀一种情况的状态。

### redo 与 undo 

- redo是数据库日志，主要是对页面（PAGE）的修改信息；undo是事务日志，记录的是对记录（TUPLE）的变更，是更高一层的抽象。崩溃发生前一刻，许多对数据库的写入还没有被持久化了页面上，这时就需要靠redo恢复到崩溃发生前的瞬间。数据库恢复完成后，数据库可能发现有一些正在运行中的事务，事务的上下文都已经丢失了，要对这些事务回滚，这时就需要undo来恢复记录原来的值。
- undo是一条记录被更新之前写入的，“写undo”这个操作，本身也是对页面的修改，也会有对应的redo。而redo每一次写页面都会记。
- 页面是分槽页（slot-page）结构，整体上看存储结构就是页面->区->段三层结构。redo是物理逻辑日志，undo是逻辑日志，概念上是这样的。undo也作为MVCC的版本链，一个undo就是前版本和后版本之前的差异。

update(Insert与之类似)操作：

- 计算更新后tuple到原tuple的delta信息，把这个delta复制到rollback segment中的undo
- 写redo log，记录对rollback segment的更改
- 把buffer pool中的对应tuple更新成新值，把新值的rollback pointer写入undo log
- 写redo log，记入对页（page）的更改
- 将页状态改成dirty

### 刷新规则

-  InnoDB 的 redo log 写满了了。这时候系统会停 ⽌止所有更更新操作，把 checkpoint 往前推进，redo log 留留出空间可以 继续写。checkpoint 可不不是随便便往前修改⼀一下位置就可以的。⽐比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的⽇日志(浅绿⾊色 部分)，对应的所有脏⻚页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写⼊入的 redo log 的区域。
- 系统内存不不⾜足。当需要新的内存⻚页，⽽而内存不不 够⽤用的时候，就要淘汰⼀一些数据⻚页，空出内存给别的数据⻚页使⽤用。如 果淘汰的是“脏⻚页”，就要先将脏⻚页写到磁盘。
-  MySQL 认为系统“空闲”的时候。
-  MySQL 正常关闭的情况

四种场景对性能的影响：

第三种情况是属于 MySQL 空闲时的操作，这时系统没什什么压⼒力力， ⽽而第四种场景是数据库本来就要关闭了了。这两种情况下，你不不会太关 注“性能”问题。所以这⾥里里，我们主要来分析⼀一下前两种场景下的性能问 题。

第⼀种是“redo log 写满了了，要 flush 脏⻚页”，这种情况是 InnoDB 要尽量量 避免的。因为出现这种情况的时候，整个系统就不不能再接受更更新了了，所有 的更更新都必须堵住。如果你从监控上看，这时候更更新数会跌为 0。

第⼆种是“内存不不够⽤用了了，要先将脏⻚页写到磁盘”，这种情况其实是常态。

InnoDB ⽤用缓冲池(buffer pool)管理理内存，缓冲池中的内存⻚页有三种状 态:

- 第⼀一种是，还没有使⽤用的; 
- 第⼆二种是，使⽤用了了并且是⼲干净⻚页; 
- 第三种是，使⽤用了了并且是脏⻚页。

InnoDB 的策略略是尽量量使⽤用内存，因此对于⼀一个⻓长时间运⾏行行的库来说，未 被使⽤用的⻚页⾯面很少。

⽽而当要读⼊入的数据⻚页没有在内存的时候，就必须到缓冲池中申请⼀一个数据 ⻚页。这时候只能把最久不不使⽤用的数据⻚页从内存中淘汰掉:如果要淘汰的是 ⼀一个⼲干净⻚页，就直接释放出来复⽤用;但如果是脏⻚页呢，就必须将脏⻚页先刷 到磁盘，变成⼲干净⻚页后才能复⽤用。

### InnoDB 刷脏⻚的控制策略

⾸首先，你要正确地告诉 InnoDB 所在主机的 IO 能⼒力力，这样 InnoDB 才能知 道需要全⼒力力刷脏⻚页的时候，可以刷多快。

这就要⽤用到 innodb_io_capacity 这个参数了了，它会告诉 InnoDB 你的磁盘 能⼒力力。这个值我建议你设置成磁盘的 IOPS。

如果刷太慢，会出现什什么情况?⾸首先是内存脏⻚页太 多，其次是 redo log 写满。

所以，InnoDB 的刷盘速度就是要参考这两个因素:⼀一个是脏⻚页⽐比例例，⼀一 个是 redo log 写盘速度。

InnoDB 会根据这两个因素先单独算出两个数字。

参数 innodb_max_dirty_pages_pct 是脏⻚页⽐比例例上限，默认值是 75%。 InnoDB 会根据当前的脏⻚页⽐比例例(假设为 M)，算出⼀一个范围在 0 到 100 之间的数字 F1(M)

InnoDB 每次写⼊入的⽇日志都有⼀一个序号，当前写⼊入的序号跟 checkpoint 对 应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出⼀一个范 围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。

然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较⼤大的值记为 R， 之后引擎就可以按照 innodb_io_capacity 定义的能⼒力力乘以 R% 来控制刷 脏⻚页的速度。


接下来，我们再看⼀一个有趣的策略略。

⼀一旦⼀一个查询请求需要在执⾏行行过程中先 flush 掉⼀一个脏⻚页时，这个查询就 可能要⽐比平时慢了了。⽽而 MySQL 中的⼀一个机制，可能让你的查询会更更慢: 在准备刷⼀一个脏⻚页的时候，如果这个数据⻚页旁边的数据⻚页刚好是脏⻚页，就 会把这个“邻居”也带着⼀一起刷掉;⽽而且这个把“邻居”拖下⽔水的逻辑还可以 继续蔓延，也就是对于每个邻居数据⻚页，如果跟它相邻的数据⻚页也还是脏 ⻚页的话，也会被放到⼀一起刷。

在 InnoDB 中，innodb_flush_neighbors 参数就是⽤用来控制这个⾏行行为的， 值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不不找邻居，⾃自⼰己刷⾃自 ⼰己的。

⽽而如果使⽤用的是 SSD 这类 IOPS ⽐比较⾼高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不不是瓶颈，

### redo log 与 页断裂问题

#### 页断裂与数据库一致性

前面我们分析了异常重启一定会导致页断裂，而页断裂就意味着数据库页面不完整，那么数据库页面不完整是否就意味着数据库不一致呢？？？我们知道，数据库异常重启时，自身有异常恢复机制，我这里不打算展开讲异常恢复机制，因为不同数据库的异常恢复流程不同。主流数据库基本原理类似：第一阶段重做redo日志，恢复数据页和undo页到异常crash时的状态；第二阶段，根据undo页的内容，回滚没有提交事务的修改。通过两个阶段保证了数据库的一致性。对于mysql而言，在第一阶段，若出现页断裂问题，则无法通过重做redo日志恢复，进而导致恢复中断，数据库不一致。这里大家可能会有疑问，数据库的redo不是记录了所有的变更，并且是物理的吗？理论上来说，无论页面是否断裂，从上一个检查点对应的redo位置开始，一直重做redo，页面自然能恢复到正常状态。对吗？讲清楚这个问题，先讲讲重做日志(redo)格式。

#### 重做日志(redo)格式

数据库系统实现日志主要有三种格式，逻辑日志(logical logging)，物理日志(physical logging)，物理逻辑日志(physiological logging)，而对于redo日志，则主要采用物理日志和物理逻辑日志两类。逻辑日志，记录一个个逻辑操作，不涉及物理存储位置信息，比如mysql的binlog；物理日志，则是记录一个个具体物理位置的操作，比如在2号表空间，1号文件，48页的233这个offset地方写入了8个字节的数据，通过(group_id,file_id,page_no,offset)4元组，就能唯一确定数据存储在磁盘的物理位置；物理逻辑日志是物理日志和逻辑日志的混合，如果一个数据库操作(DDL，DML，DCL)产生的日志跨越了多个页面，那么会产生多个物理页面的日志，但对于每个物理页面日志，里面记录则是逻辑信息。这里我举一个简单的INSERT操作来说明几种日志形式。

比如innodb表T(c1,c2, key key_c1(c1)),插入记录row1(1,’abc’)

逻辑日志：

<insert OP, T, 1,’abc’>

逻辑物理日志：

因为表T含有索引key_c1, 一次插入操作至少涉及两次B树操作，二次B树必然涉及至少两个物理页面,因此至少有两条日志

<insert OP, page_no_1, log_body>

<insert OP, page_no_2, log_body>

物理日志:

由于一次INSERT操作，物理上来说要修改页头信息(如,页内的记录数要加1)，要修改相邻记录里的链表指针，要修改Slot属性等，因此对应逻辑物理日志的每一条日志，都会有N条物理日志产生。

< group_id,file_id,page_no,offset1, value1>

< group_id,file_id,page_no,offset2, value2>

……

< group_id,file_id,page_no,offsetN, valueN>

 

因此对于上述一个INSERT操作，会产生一条逻辑日志，二条逻辑物理日志，2*N条物理日志。从上面简单的分析可以看出，逻辑日志的日志量最小，而物理日志的日志量最大；物理日志是纯物理的；而逻辑物理日志则页间物理，页内逻辑，所谓physical-to-a-page, logical-within-a-page。

#### redo格式与数据一致性

回到“发生页断裂后，是否会影响数据库一致性”的问题，发生页断裂后，对于利用纯物理日志实现redo的数据库不受影响，因为每一条redo日志完全不依赖物理页的状态，并且是幂等的(执行一次与N次，结果是一样的)。另外要说明一点，redo日志的页大小一般设计为512个字节，因此redo日志页本身不会发生页断裂。而逻辑物理日志则不行，比如修改页头信息，页内记录数加1，slot信息修改等都依赖于页面处于一个一致状态，否则就无法正确重做redo。而mysql正是采用这种日志类型，所以发生页面断裂时，异常恢复就会出现问题，需要借助于double write技术来辅助处理。


#### double write处理页断裂

doublewrite是Innodb表空间内部分配的一片缓冲区，一般double write包含128个页，对于pagesize为16k的页，总共2MB，doublewrite页与数据页一样有物理存储空间，存在于共享表空间中。Innodb在写出缓冲区中的数据页时采用的是一次写多个页的方式，这样多个页就可以先顺序写入到doublewrite缓冲区，并调用fsync()保证这些数据被写出到磁盘，然后数据页才被写出到它们实际的存储位置并再次调用fsync()。故障恢复时Innodb检查doublewrite缓冲区与数据页原存储位置的内容，若doublewrite页处于页断裂状态，则简单的丢弃；若数据页不一致，则会从doublewrite页还原。由于doublewrite页落盘与数据页落盘在不同的时间点，不会出现doublewrite页和数据页同时发生断裂的情况，因此doublewrite技术可以解决页断裂问题，进而保证了重做日志能顺利进行，数据库能恢复到一致的状态。

## Mysql binlog

### binlog 与 redo log 的不同

前⾯面我们讲过，MySQL 整体来看，其实就有两块:⼀一块是 Server 层，它 主要做的是 MySQL 功能层⾯面的事情;还有⼀一块是引擎层，负责存储相关 的具体事宜。上⾯面我们聊到的粉板 redo log 是 InnoDB 引擎特有的⽇日志， ⽽而 Server 层也有⾃自⼰己的⽇日志，称为 binlog(归档⽇日志)。

为什么会有两份⽇日志呢?

因为最开始 MySQL ⾥里里并没有 InnoDB 引擎。MySQL ⾃自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能⼒力力，binlog ⽇日志只能⽤用于归 档。⽽而 InnoDB 是另⼀一个公司以插件形式引⼊入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能⼒力力的，所以 InnoDB 使⽤用另外⼀一套⽇日志系统 ——也就是 redo log 来实现 crash-safe 能⼒力力。

这两种⽇日志有以下三点不不同。

- redo log 是 InnoDB 引擎特有的;binlog 是 MySQL 的 Server 层实现 的，所有引擎都可以使⽤用。
- redolog是物理⽇志，记录的是“在某个数据⻚页上做了什么修改”; binlog 是逻辑日志，记录的是这个语句的原始逻辑，⽐如“给 ID=2 这⼀⾏行行的 c 字段加 1 ”。
- redolog是循环写的，空间固定会⽤用完;binlog是可以追加写⼊的。“追加写”是指 binlog ⽂文件写到⼀一定⼤大⼩小后会切换到下⼀一个，并 不不会覆盖以前的⽇日志。

### 两阶段提交

有了了对这两个⽇日志的概念性理理解，我们再来看执⾏行行器器和 InnoDB 引擎在执 ⾏行行这个简单的 update 语句句时的内部流程。

- 执⾏器器先找引擎取 ID=2 这⼀一⾏。ID 是主键，引擎直接⽤用树搜索找到这⼀⾏。如果 ID=2 这⼀⾏所在的数据⻚本来就在内存中，就直接返回给执⾏行行器器;否则，需要先从磁盘读⼊入内存，然后再返回。
- 执⾏器拿到引擎给的⾏数据，把这个值加上 1，⽐比如原来是 N，现在 就是 N+1，得到新的⼀一⾏数据，再调⽤用引擎接⼝口写⼊入这⾏行行新数据。
- 引擎将这⾏新数据更更新到内存中，同时将这个更更新操作记录到 redo log ⾥里里⾯面，此时 redo log 处于 prepare 状态。然后告知执⾏器器执⾏完成了了，随时可以提交事务。
- 执⾏器⽣成这个操作的 binlog，并把 binlog 写⼊入磁盘。
- 执⾏器调⽤引擎的提交事务接⼝，引擎把刚刚写⼊入的 redo log 改成提交(commit)状态，更更新完成。

![](img/redolog2.png)

### 为什么需要两阶段提交？

由于 redo log 和 binlog 是两个独⽴立的逻辑，如果不不⽤用两阶段提交，要么 就是先写完 redo log 再写 binlog，或者采⽤用反过来的顺序。我们看看这两 种⽅方式会有什什么问题。

- 先写redolog后写binlog。假设在redolog写完，binlog还没有写 完的时候，MySQL 进程异常重启。由于我们前⾯面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这 ⼀一⾏行行 c 的值是 1。
             
    但是由于 binlog 没写完就 crash 了了，这时候 binlog ⾥里里⾯面就没有记录 这个语句句。因此，之后备份⽇日志的时候，存起来的 binlog ⾥里里⾯面就没 有这条语句句。

    然后你会发现，如果需要⽤用这个 binlog 来恢复临时库的话，由于这 个语句句的 binlog 丢失，这个临时库就会少了了这⼀一次更更新，恢复出来 的这⼀一⾏行行 c 的值就是 0，与原库的值不不同。

- 先写binlog后写redolog。如果在binlog写完之后crash，由于 redo log 还没写，崩溃恢复以后这个事务⽆无效，所以这⼀一⾏行行 c 的值是 0。但是 binlog ⾥里里⾯面已经记录了了“把 c 从 0 改成 1”这个⽇日志。所以， 在之后⽤用 binlog 来恢复的时候就多了了⼀一个事务出来，恢复出来的这 ⼀一⾏行行 c 的值就是 1，与原库的值不不同。

简单的说，redo log 是用于处理数据库崩溃后恢复数据的，而 binlog 是用于数据库备份的。

当数据库崩溃后，隔 10 天后需要利用 binlog 备份来恢复数据库，那么恢复出来的数据库就会和崩溃后恢复的数据库不一致。

而两阶段提交，就会提供一个屏障，只要 binlog 写入成功了，数据就需要被恢复。数据库在 binlog 写入成功前崩溃，数据不保证恢复、binglog 写入成功，数据就会根据 binlog 与 redo log 的 prepare 记录恢复，不管 redo log 有没有 commit 记录。

此外，binlog 也用于从库的数据更新，binlog 与 redo log 不一致，也会导致主从不一致的情况。

### binlog 数据恢复过程

当需要恢复到指定的某⼀一秒时，⽐比如某天下午两点发现中午⼗十⼆二点有⼀一次 误删表，需要找回数据，那你可以这么做:

- 首先，找到最近的⼀一次全量量备份，如果你运⽓气好，可能就是昨天晚上 的⼀一个备份，从这个备份恢复到临时库;
- 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到 中午误删表之前的那个时刻。

### binlog 完整格式

- statement 格式的 binlog，最后会有 COMMIT; 
- row 格式的 binlog，最后会有⼀一个 XID event。

另外，在 MySQL 5.6.2 版本以后，还引⼊入了了 binlog-checksum 参数，⽤用 来验证 binlog 内容的正确性。对于 binlog ⽇日志由于磁盘原因，可能会在 ⽇日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。

### redo log 和 binlog 是怎么关联起来的?

它们有⼀一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log:

- 如果碰到既有 prepare、⼜又有 commit 的 redo log，就直接提交; 
- 如果碰到只有 parepare、⽽而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。


## redo log buffer 与 binlog buffer

### redo log buffer 

在⼀一个事务的更更新过程中，⽇日志是要写多次的。⽐比如下⾯面这个事务:

```
begin;insert into t1 ...insert into t2 ...commit;

```

这个事务要往两个表中插⼊入记录，插⼊入数据的过程中，⽣生成的⽇日志都得先 保存起来，但⼜又不不能在还没 commit 的时候就直接写到 redo log ⽂文件⾥里里。

所以，redo log buffer 就是⼀一块内存，⽤用来先存 redo ⽇日志的。也就是 说，在执⾏行行第⼀一个 insert 的时候，数据的内存被修改了了，redo log buffer 也写⼊入了了⽇日志。

但是，真正把⽇日志写到 redo log ⽂文件(⽂文件名是 ib_logfile+ 数字)，是在 执⾏行行 commit 语句句的时候做的。

这⾥说的是事务执⾏行行过程中不不会“主动去刷盘”，以减少不不必要的 IO 消 耗。但是可能会出现“被动写⼊入磁盘”，⽐比如内存不不够、其他事务提交等情况。

### redo log 的写⼊机制

redo log buffer ⾥里里⾯面的内容，是不不是每次⽣生成后都要 直接持久化到磁盘呢?

答案是，不不需要。

如果事务执⾏行行期间 MySQL 发⽣生异常重启，那这部分⽇日志就丢了了。由于事 务并没有提交，所以这时⽇日志丢了了也不不会有损失。
那么，另外⼀一个问题是，事务还没提交的时候，redo log buffer 中的部分 ⽇日志有没有可能被持久化到磁盘呢?

答案是，确实会有。

redo log 可能存在的三种状态说起。这三种状态，对应的 就是图 2 中的三个颜⾊色块。

![](img/redo1.png)

这三种状态分别是:
     
- 存在 redo log buffer 中，物理理上是在 MySQL 进程内存中，就是图中 的红⾊色部分;
- 写到磁盘 (write)，但是没有持久化(fsync)，物理理上是在⽂文件系统的 page cache ⾥里里⾯面，也就是图中的⻩黄⾊色部分;
- 持久化到磁盘，对应的是 hard disk，也就是图中的绿⾊色部分。

⽇日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不不多，但是持久化到磁盘的速度就慢多了了。

为了了控制 redo log 的写⼊入策略略，InnoDB 提供了了innodb_flush_log_at_trx_commit 参数，它有三种可能取值:

- 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留留在 redo log buffer 中 ;
- 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁 盘;
- 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

InnoDB 有⼀一个后台线程，每隔 1 秒，就会把 redo log buffer 中的⽇日志， 调⽤用 write 写到⽂文件系统的 page cache，然后调⽤用 fsync 持久化到磁盘。

注意，事务执⾏行行中间过程的 redo log 也是直接写在 redo log buffer 中的， 这些 redo log 也会被后台线程⼀一起持久化到磁盘。也就是说，⼀一个没有提 交的事务的 redo log，也是可能已经持久化到磁盘的。

实际上，除了了后台线程每秒⼀一次的轮询操作外，还有两种场景会让⼀一个没有提交的事务的 redo log 写⼊入到磁盘中。

-  ⼀种是，redologbuffer占⽤用的空间即将达到 innodb_log_buffer_size ⼀一半的时候，后台线程会主动写盘。注意， 由于这个事务并没有提交，所以这个写盘动作只是 write，⽽而没有调 ⽤用 fsync，也就是只留留在了了⽂文件系统的 page cache。
-  另⼀种是，并⾏行行的事务提交的时候，顺带将这个事务的redolog buffer 持久化到磁盘。假设⼀一个事务 A 执⾏行行到⼀一半，已经写了⼀些 redo log 到 buffer 中，这时候有另外⼀一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻 辑，事务 B 要把 redo log buffer ⾥里里的⽇日志全部持久化到磁盘。这时 候，就会带上事务 A 在 redo log buffer ⾥里里的⽇日志⼀一起持久化到磁 盘。

这⾥里里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。

如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化⼀一次，因为有⼀一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。

每秒⼀一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不不需要 fsync 了了，只会 write 到⽂文件系统的 page cache 中就够了了。

### binlog buffer

binlog 的写⼊入逻辑⽐比较简单:事务执⾏行行过程中，先把⽇日志写到inlog cache，事务提交的时候，再把 binlog cache 写到 binlog ⽂文件中。

⼀一个事务的 binlog 是不不能被拆开的，因此不不论这个事务多⼤大，也要确保⼀一 次性写⼊入。这就涉及到了了 binlog cache 的保存问题。

系统给 binlog cache 分配了了⼀一⽚片内存，每个线程⼀一个，参数 binlog_cache_size ⽤用于控制单个线程内 binlog cache 所占内存的⼤大⼩小。 如果超过了了这个参数规定的⼤大⼩小，就要暂存到磁盘。

事务提交的时候，执⾏行行器器把 binlog cache ⾥里里的完整事务写⼊入到 binlog 中，并清空 binlog cache。

![](img/binlog1.png)

可以看到，每个线程有⾃自⼰己 binlog cache，但是共⽤用同⼀一份 binlog ⽂文件。

- 图中的 write，指的就是指把⽇日志写⼊入到⽂文件系统的 page cache，并 没有把数据持久化到磁盘，所以速度⽐比较快。
- 图中的 fsync，才是将数据持久化到磁盘的操作。⼀一般情况下，我们 认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的:

- sync_binlog=0 的时候，表示每次提交事务都只 write，不不 fsync; 
- sync_binlog=1 的时候，表示每次提交事务都会执⾏行行 fsync;
- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

因此，在出现 IO 瓶颈的场景⾥里里，将 sync_binlog 设置成⼀一个⽐比较⼤大的值， 可以提升性能。在实际的业务场景中，考虑到丢失⽇日志量量的可控性，⼀一般 不不建议将这个参数设成 0，⽐比较常⻅见的是将其设置为 100~1000 中的某个 数值。

但是，将 sync_binlog 设置为 N，对应的⻛风险是:如果主机发⽣生异常重 启，会丢失最近 N 个事务的 binlog ⽇日志。


### redo log buffer 与 binlog buffer 的持久化配合

通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，⼀一个事务完整提 交前，需要等待两次刷盘，⼀一次是 redo log(prepare 阶段)，⼀一次是 binlog。

这时候，你可能有⼀一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两 万的话，每秒就会写四万次磁盘。但是，我⽤用⼯工具测试出来，磁盘能⼒力力也 就两万左右，怎么能实现两万的 TPS?

解释这个问题，就要⽤用到组提交(group commit)机制了了。

这⾥里里，我需要先和你介绍⽇日志逻辑序列列号(log sequence number， LSN)的概念。LSN 是单调递增的，⽤用来对应 redo log 的⼀一个个写⼊入点。 每次写⼊入⻓长度为 length 的 redo log， LSN 的值就会加上 length。

LSN 也会写到 InnoDB 的数据⻚页中，来确保数据⻚页不不会被多次执⾏行行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后⾯面的⽂文章 中详细展开。

如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。

![](img/redo2.png)

从图中可以看到，

- trx1 是第⼀一个到达的，会被选为这组的 leader;
- 等 trx1 要开始写盘的时候，这个组⾥里里⾯面已经有了了三个事务，这时候 LSN 也变成了了 160;
- trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN ⼩小于等于 160 的 redo log，都已经被持久化到磁盘;
- 这时候 trx2 和 trx3 就可以直接返回了了。

所以，⼀一次组提交⾥里里⾯面，组员越多，节约磁盘 IOPS 的效果越好。

在并发更更新场景下，第⼀一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调⽤用，组员可能越多，节约 IOPS 的效果就越好。

实际上，写 binlog 是分成两步 的:

- 先把 binlog 从 binlog cache 中写到磁盘上的 binlog ⽂文件;
- 调⽤用 fsync 持久化。

![](img/redo3.png)

上图是一个事务提交的过程，在事务提交之前，binlog buffer 存储着未提交的日志，redo log buffer 里面存储着未提交的日志。

- 当事务 commit 的时候，redo log buffer 首先进行 prepare 的 write，将其写到 redo log 的操作系统 page cache 中
- 进行 binlog buffer 的 write，写到 binlog 文件的 page cache 中
- 然后才进行 redo log 的 prepare 记录的 fsync，这个时候会将其他的或已提交的或未提交的事务 redo log buffer 都持久化到磁盘中
- 进行 binlog 的 fsync 持久化，这个持久化至关重要，因为它才标志着事务的真正提交。
- 进行 redo log 的 commit 记录 write，无需持久化，因为 binlog 持久化已完成，这个 commit 记录丢失也无所谓。


这么⼀一来，binlog 也可以组提交了了。在执⾏行行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了了，也是⼀一起持久化的，这样也可以减少 IOPS 的消耗。

不不过通常情况下第 3 步执⾏行行得会很快，所以 binlog 的 write 和 fsync 间的 间隔时间短，导致能集合到⼀一起持久化的 binlog ⽐比较少，因此 binlog 的 组提交的效果通常不不如 redo log 的效果那么好。

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

- binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调⽤用 fsync;
- binlog_group_commit_sync_no_delay_count参数，表示累积多少次 以后才调⽤用 fsync。

现在你就能理理解了了，WAL 机制主要得益于两个⽅方⾯面:

- redolog和binlog都是顺序写，磁盘的顺序写⽐比随机写速度要快;
- 组提交机制，可以⼤大幅度降低磁盘的 IOPS 消耗。
